{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    cohen_kappa_score\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "\n",
    "# File Paths\n",
    "TRAIN_PATH = \"dataset/train_interpolated.csv\"\n",
    "VALID_PATH = \"dataset/valid_interpolated.csv\"\n",
    "TEST_PATH  = \"dataset/test_interpolated.csv\"\n",
    "\n",
    "# Crop ID to Name mapping\n",
    "CROP_MAPPING = {\n",
    "    27: \"Sesame\", 2: \"Pepper\", 8: \"Aralia\", 1: \"Sweet potato\",\n",
    "    17: \"Sudangrass\", 29: \"Soybean\", 9: \"Perilla\", 19: \"Greenhouse\",\n",
    "    24: \"Yuzu\", 23: \"Maize\", 28: \"Kiwi\", 22: \"Onion\",\n",
    "    16: \"Apple\", 30: \"Grape\", 14: \"Peach\", 10: \"Garlic\",\n",
    "    12: \"Pear\", 13: \"Cabbage\", 11: \"Sapling\", 31: \"Radish\"\n",
    "}\n",
    "\n",
    "# Feature definitions (Bands and Time steps)\n",
    "BANDS = ['b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b08', 'b8a', 'b11', 'b12']\n",
    "MONTHS = [f\"2021{m:02d}\" for m in range(7, 13)]\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"--- Loading Data ---\")\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_valid = pd.read_csv(VALID_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# 2. Apply Mapping & Preprocessing\n",
    "# Ensure crop names exist and remove invalid rows\n",
    "for df in (df_train, df_valid, df_test):\n",
    "    df[\"crop_name\"] = df[\"CR_ID\"].map(CROP_MAPPING)\n",
    "    df.dropna(subset=[\"crop_name\"], inplace=True)\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Valid shape: {df_valid.shape}\")\n",
    "print(f\"Test shape:  {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Feature List\n",
    "# Construct feature column names: {band}_{YYYYMM}_{interval}\n",
    "features = [f\"{b}_{mon}_{d}\" for b in BANDS for mon in MONTHS for d in range(1, 4)]\n",
    "print(f\"Number of input features: {len(features)}\")\n",
    "\n",
    "# 4. Prepare X (Features) and y (Target)\n",
    "le = LabelEncoder().fit(df_train[\"crop_name\"])\n",
    "\n",
    "X_train = df_train[features].values\n",
    "y_train = le.transform(df_train[\"crop_name\"])\n",
    "\n",
    "X_valid = df_valid[features].values\n",
    "y_valid = le.transform(df_valid[\"crop_name\"])\n",
    "\n",
    "X_test  = df_test[features].values\n",
    "y_test  = le.transform(df_test[\"crop_name\"])\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train Random Forest Classifier\n",
    "print(\"--- Training Model ---\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    random_state=42, \n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate on Validation Set\n",
    "print(\"\\n=== Validation Set Performance ===\")\n",
    "y_pred_val = rf.predict(X_valid)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_valid, y_pred_val):.4f}\")\n",
    "\n",
    "# 7. Evaluate on Test Set\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "start_time = time.time()  \n",
    "y_pred_test = rf.predict(X_test)\n",
    "end_time = time.time()    \n",
    "\n",
    "# Calculate Metrics\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "macro_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "weighted_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "kappa = cohen_kappa_score(y_test, y_pred_test)\n",
    "\n",
    "# Print Metrics\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_test, y_pred_test, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Complexity & Efficiency Analysis\n",
    "print(\"\\n=== Model Complexity & Efficiency ===\")\n",
    "\n",
    "# Calculate total number of nodes across all trees in the forest\n",
    "n_params = sum([tree.tree_.node_count for tree in rf.estimators_])\n",
    "print(f\"Total Parameters (Total Nodes): {n_params}\")\n",
    "\n",
    "# Calculate inference speed per sample\n",
    "inference_time_total = end_time - start_time\n",
    "inference_time_ms_per_sample = (inference_time_total / len(X_test)) * 1000\n",
    "print(f\"Inference Time: {inference_time_ms_per_sample:.4f} ms/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost Model\n",
    "print(\"--- Training XGBoost Model ---\")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# Fit the model with validation monitoring\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate on Validation Set\n",
    "print(\"\\n=== Validation Set Performance ===\")\n",
    "y_pred_val = xgb.predict(X_valid)\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, y_pred_val):.4f}\")\n",
    "print(classification_report(y_valid, y_pred_val, target_names=le.classes_))\n",
    "\n",
    "# 2. Evaluate on Test Set\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "start_time = time.time() \n",
    "y_pred_test = xgb.predict(X_test)\n",
    "end_time = time.time()   \n",
    "\n",
    "# Calculate Metrics\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "macro_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "weighted_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "kappa = cohen_kappa_score(y_test, y_pred_test)\n",
    "\n",
    "# Print Metrics\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(y_test, y_pred_test, target_names=le.classes_))\n",
    "\n",
    "# 3. Model Complexity & Efficiency Analysis\n",
    "print(\"\\n=== Model Complexity & Efficiency ===\")\n",
    "\n",
    "# Calculate Total Parameters (Total Nodes in all trees)\n",
    "booster = xgb.get_booster()\n",
    "df_trees = booster.trees_to_dataframe()\n",
    "n_params = df_trees.shape[0]\n",
    "print(f\"Total Parameters (Total Nodes): {n_params}\")\n",
    "\n",
    "# Calculate Inference Time\n",
    "inference_time_total = end_time - start_time\n",
    "inference_time_ms_per_sample = (inference_time_total / len(X_test)) * 1000\n",
    "print(f\"Inference Time: {inference_time_ms_per_sample:.4f} ms/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "print(\"--- Plotting Confusion Matrix ---\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8)) # Adjusted size for better visibility\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "\n",
    "# Display plot\n",
    "disp.plot(cmap=\"Blues\", ax=ax, xticks_rotation=90)\n",
    "ax.set_title(\"XGBoost Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
